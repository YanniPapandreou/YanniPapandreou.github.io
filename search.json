[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I‚Äôve just joined Moody‚Äôs RMS as a Climate Hazard Modeller on the Tropical Cyclone team.\nPreviously, I worked as a Quantitative Researcher at Bayforest Technologies.\nBefore that I completed my PhD in Mathematics at Imperial College London under the joint supervision of Dr Andrew Duncan and Dr Jon Cockayne. My PhD research was focused on the Bayesian formulation of PDE-based models with an aim towards physics-informed machine learning. I have also worked on kernel-based methods for inference of complex models.\n\nPresent StatusExperienceEducationInterestsLanguagesCountries\n\n\nüíª Climate Hazard Modeller | Moody‚Äôs RMS | November 2024 - Present\nüè† Based in London\n\n\nüíª Quantitative Researcher | Bayforest Technologies | September 2023 - November 2024\nüíª AI Research Intern | Arabesque AI | August 2021 - November 2021\nüìñ Mathematics Tutor | Keystone Tutors | December 2019 - September 2023\nüìñ Graduate Teaching Assistant (GTA) | Imperial College London | October 2019 - September 2023\n\n\nüéì PhD in Mathematics | Imperial College London | October 2019 - September 2023\nüéì MSc in Statistics | Imperial College London | September 2018 - September 2019\nüéì BA in Mathematics | University of Cambridge | October 2015 - June 2018\n\n\nüíª Programming | Nix | Python | Julia | R\nüìö Mathematics | Bayesian Statistics | Physics-informed ML | Kernel-based methods\n\n\nüí¨ English (native) | Greek (conversational)\n\n\nüåê UK (Current; ‚âà9 years) | Cyprus (‚âà11 years) | USA (‚âà10 years)\n\n\n\n Download my CV"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "YP",
    "section": "",
    "text": "Hi there, I‚Äôm Yanni üëã. I‚Äôm a statistician and you can find more about me here.\nI will be posting on topics I find interesting here. Any mistakes contained in such posts are mine and mine alone.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up Jupyter Lab with Additional Kernels in NixOS\n\n\n\n\n\n\nNix\n\n\nProgramming\n\n\nR\n\n\nPython\n\n\nRust\n\n\n\n\n\n\n\n\n\nMar 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBitwise Logical Operations in R\n\n\n\n\n\n\nR\n\n\nProgramming\n\n\n\n\n\n\n\n\n\nSep 20, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bitwise_ops_r/index.html",
    "href": "posts/bitwise_ops_r/index.html",
    "title": "Bitwise Logical Operations in R",
    "section": "",
    "text": "Recently I‚Äôve been refreshing my knowledge of R by going over problems from the R track on Exercism. A recurring technique needed1 for the problems in these tracks is to be able to convert integers into their binary representation."
  },
  {
    "objectID": "posts/bitwise_ops_r/index.html#explanation",
    "href": "posts/bitwise_ops_r/index.html#explanation",
    "title": "Bitwise Logical Operations in R",
    "section": "Explanation",
    "text": "Explanation\nLet‚Äôs now explain how this function works. The key idea of this function is to use the bitwise and operation to extract the \\(i^{\\text{th}}\\) digit of the binary representation of \\(n\\) as follows:\n\nget_binary_digit &lt;- function(n, i){\n  out &lt;- bitwAnd(n, 2 ^ (i - 1))\n  as.integer(out &gt; 0)\n}\n\nThis works because we perform a bitwise and operation on the binary representations of \\(n\\) with the binary representation of the appropriate power of 2. The binary representation of \\(2^{i - 1}\\) has a single 1 in the \\(i^{\\text{th}}\\) position and so performing this bitwise and operation with the binary representation of \\(n\\) will result in a binary vector with all zeros apart from perhaps a single 1 located in the \\(i^{\\text{th}}\\) position if and only if there is a 1 in the representation of \\(n\\). Since the bitwAnd function returns the result not as a binary vector but as the integer the binary vector represents we convert the result to the appropriate binary digit by testing if the output is positive6.\n\n\n\n\n\n\nNote\n\n\n\nThis is akin to finding the \\(i^{\\text{th}}\\) coordinate of a vector \\(\\mathbf{v}\\) in a given orthogonal basis \\(\\{\\mathbf{e}_{i}\\}_{i}\\) by taking the dot product of the vector with the \\(i^{\\text{th}}\\) basis vector:\n\\[\n\\mathbf{v} = \\sum_{i} v_{i} \\mathbf{v}_{i}\n\\]\nwhere the coefficient \\(v_{i}\\) is given by:\n\\[\nv_{i} = \\langle \\mathbf{v}, \\mathbf{e}_{i}\\rangle\n\\]\nIn the binary representation problem above the binary representations of powers of 2 can be thought of as the orthogonal basis - in fact as a sort of canonical basis for the representation.\n\n\nThus, the line as.integer(bitwAnd(n, 2 ^ (limit:0)) &gt; 0) in Listing¬†2 simply extracts all the binary digits of \\(n\\) in a vectorised fashion7."
  },
  {
    "objectID": "posts/bitwise_ops_r/index.html#footnotes",
    "href": "posts/bitwise_ops_r/index.html#footnotes",
    "title": "Bitwise Logical Operations in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIndeed in many of the tracks and in computer science in general.‚Ü©Ô∏é\nSince \\(17 = 16 + 1 = 2^4 + 2^0\\).‚Ü©Ô∏é\nTo see the full docs run ?bitwAnd in an R console.‚Ü©Ô∏é\nWith the convention that the bit 1 represents TRUE and 0 represents FALSE.‚Ü©Ô∏é\nNote that the binary representation is left padded with zeros so the lengths match.‚Ü©Ô∏é\nThe output will be positive if and only if the \\(i^{\\text{th}}\\) binary digit was a 1.‚Ü©Ô∏é\nThe defintion of limit as floor(log2(n)) is simply 1 less than the number of binary digits in \\(n\\).‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/jupyter-kernels-nix/index.html",
    "href": "posts/jupyter-kernels-nix/index.html",
    "title": "Setting up Jupyter Lab with Additional Kernels in NixOS",
    "section": "",
    "text": "Recently, I‚Äôve been trying to experiment more with plotting in R using ggplot2 and plotly for more interactive visualizations. As part of this experimentation I‚Äôve tried to setup Jupyter Lab on my personal laptop where I have been daily driving NixOS for the last few years. In the past, and during my PhD I was mainly coding in Python and using Jupyter with Python on NixOS was quite straight-forward. However, as I now am using R in my job I‚Äôve tried to also setup my dev environment on my personal computer for R using Nix. My main workflow so far resolves around using Radian as my R console and coding with Neovim as my IDE, tying the two together with Zellij. However, as I‚Äôve lately been experimenting more with plotting in R I‚Äôve wanted to start using Jupyter Lab again for a more visual iterative REPL driven workflow. Achieving this took a bit more digging than I thought necessary. As such, I‚Äôm collating my notes here, mainly as a reference for my future self and in case anyone else is also struggling with this."
  },
  {
    "objectID": "posts/jupyter-kernels-nix/index.html#footnotes",
    "href": "posts/jupyter-kernels-nix/index.html#footnotes",
    "title": "Setting up Jupyter Lab with Additional Kernels in NixOS",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese warnings do not show up in the rendered Quarto post here however they are shown during rendering on the terminal and look like rm: cannot remove '/tmp/RtmpwpDMPU/file98da433fe3ad/kernelspec/kernel.json': Permission denied‚Ü©Ô∏é\nSee Jupyter docs here for more info on this environment variable.‚Ü©Ô∏é"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Journal Articles\n\nTheoretical Guarantees for the Statistical Finite Element Method\n\nSIAM/ASA Journal on Uncertainty Quantification\nAuthors: Yanni Papandreou, Jon Cockayne, Mark Girolami, Andrew B. Duncan\nüîó PDF: A pdf version () can be found here.\nüîó Code: The code for this paper is publicly available here.\n\n\n\n\n\nConference Papers\n\nRandom Grid Neural Processes for Parametric Partial Differential Equations\n\nProceedings of the 40th International Conference on Machine Learning\nAuthors: Arnaud Vadeboncoeur, Ieva Kazlauskaite, Yanni Papandreou, Fehmi Cirak, Mark Girolami, √ñmer Deniz Akyildiz\nüîó PDF: A version can be found here.\n\n\n\n\nTheses\n\nBayesian uncertainty quantification for PDE models: new perspectives on inference and dimension reduction\n\nPhD Thesis | Imperial College London\nSupervisors: Dr Andrew B. Duncan, Dr Jon Cockayne\nüîó PDF: A version can be found here.\nüîó Code: Code associated with this thesis can be found at the following GitHub repositories:\n\nstatFEM_analysis\ngrassgp\n\n\nKernel-Based Inference Methods for Ordinary Differential Equations\n\nMSc Thesis | Imperial College London\nSupervisors: Dr Andrew B. Duncan\nüîó PDF/Code: A pdf version of this thesis, together with some code, can be found in the GitHub repository here."
  }
]